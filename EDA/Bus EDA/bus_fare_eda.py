# -*- coding: utf-8 -*-
"""Bus Fare EDA

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/10CPuvJVi4MReVK0l6yygoCEjyBGUnGnn
"""

import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
import numpy as np
from scipy.stats.mstats import winsorize
from sklearn.preprocessing import StandardScaler, MinMaxScaler

"""# Task
analyse and check for missingvalues and outliers

Here is all the data you need:
"test.csv"

## Data loading

### Subtask:
Load the data from the provided CSV file into a pandas DataFrame.

**Reasoning**:
Load the data from the provided CSV file into a pandas DataFrame and display the first few rows.
"""

df = pd.read_csv('/content/bus fare dataset.csv')
df
#head.()- display the first 5 rows of the dataset

df.head(20)

"""## Data exploration

### Subtask:
Explore the loaded data to understand its structure and basic statistics.

**Reasoning**:
I need to explore the data's structure, data types, descriptive statistics, unique values in categorical columns, and display the first few rows to understand the data better. This can be done in a single code block.
"""

# Check dimensions
print("Shape of the DataFrame:", df.shape)

# Examine data types
print("\nData types of each column:")
print(df.info())

# Descriptive statistics for numerical columns
print("\nDescriptive statistics for numerical columns:")
display(df.describe())
display(df.describe(include= "O"))
# Display first few rows
print("\nFirst few rows of the DataFrame:")
display(df.head())

# Unique values in categorical columns
print("\nUnique values in categorical columns:")
for col in ['Sex', 'Embarked']:  # Example categorical columns
    print(f"\nColumn '{col}':")
    print(df[col].unique())
    print(df[col].value_counts())

df["PassengerId"].nunique()

df['Sex'].value_counts()

df['PassengerId'].value_counts()

df.columns

df['Pclass'].value_counts()
#418 rowws- 3 uniques r4eapted - discrete

df['SibSp'].value_counts()

df['Parch'].value_counts()

df['Parch'].nunique()

for col in df.columns:  # Example categorical columns
    print(f"\nColumn '{col}':")
    print(df[col].nunique())
    print(df[col].value_counts())
    print("---------------------------------------------")

df.info()

#age fare and cabin -- missing values in each column
df.isnull().sum()

df["Fare"].nunique()

#% of missing values in a column
missing_values = df.isnull().sum() # how many missing values in the column
missing_percentage = (missing_values / len(df)) * 100 # len----> no of rows

print("\nMissing Value Percentage:\n", missing_percentage)

n_col=['Age', 'SibSp', 'Parch','Fare']
for col in n_col:
  plt.figure(figsize=(8, 5))
  sns.boxplot(x=df[col])

#fare and age imputation--- continous --- shape of the column
#histogram making
plt.figure(figsize=(12, 5))
plt.hist(df["Age"])
plt.show()

#skewd--- median

#fare and age imputation--- continous --- shape of the column
#histogram making
plt.hist(df["Fare"],bins=50)
plt.show()

#skewd--- median

df["Fare"].mode()

df["Fare"].median()

df["Fare"].value_counts()

# cabinet --- delete
#age-- median -- outlier
#fare-- mode --

"""## Data analysis

### Subtask:
Analyze the data for missing values and potential outliers.

**Reasoning**:
Calculate the number and percentage of missing values, detect outliers in numerical columns using IQR, and examine categorical columns for unusual values.
"""

# Box plots for 'Age' and 'Fare'
plt.figure(figsize=(12, 5))

sns.boxplot(y=df['Age'])
plt.title('Box Plot of Age')

def detect_outliers_iqr(data):
    Q1 = data.quantile(0.25)
    Q3 = data.quantile(0.75)
    IQR = Q3 - Q1
    lower_bound = Q1 - 1.5 * IQR
    upper_bound = Q3 + 1.5 * IQR
    outliers = data[(data < lower_bound) | (data > upper_bound)]
    return outliers

age_outliers = detect_outliers_iqr(df['Age'])


print("\nAge Outliers:\n", age_outliers)

sns.boxplot(y=df['Fare']) #verticle orientation
plt.title('Box Plot of Fare')
plt.show()

fare_outliers = detect_outliers_iqr(df['Fare'])

print("\nFare Outliers:\n", fare_outliers)

# Missing Value Analysis
missing_values = df.isnull().sum()
missing_percentage = (missing_values / len(df)) * 100
print("Missing Values:\n", missing_values)
print("\nMissing Value Percentage:\n", missing_percentage)

# Outlier Detection (IQR for 'Age' and 'Fare')
def detect_outliers_iqr(data):
    Q1 = data.quantile(0.25)
    Q3 = data.quantile(0.75)
    IQR = Q3 - Q1
    lower_bound = Q1 - 1.5 * IQR
    upper_bound = Q3 + 1.5 * IQR
    outliers = data[(data < lower_bound) | (data > upper_bound)]
    return outliers

age_outliers = detect_outliers_iqr(df['Age'])
fare_outliers = detect_outliers_iqr(df['Fare'])

print("\nAge Outliers:\n", age_outliers)
print("\nFare Outliers:\n", fare_outliers)

# Categorical Column Analysis
for col in ['Embarked', 'Sex', 'Pclass']:
    print(f"\nUnique values in column '{col}':")
    print(df[col].unique())
    print(df[col].value_counts())

"""## Data visualization

### Subtask:
Visualize the distribution of data and identify outliers using histograms and box plots.

**Reasoning**:
Visualize the distribution of numerical features ('Age', 'Fare') using histograms and box plots, and visualize the relationship between 'Age' and 'Fare' using a scatter plot, colored by 'Pclass'.  Also create bar charts for the categorical features ('Embarked', 'Sex', 'Pclass').
"""

# Histograms for 'Age' and 'Fare'
plt.figure(figsize=(12, 5))
plt.subplot(1, 2, 1)
sns.histplot(df['Age'].dropna(), kde=True)
plt.title('Distribution of Age')

plt.subplot(1, 2, 2)
sns.histplot(df['Fare'].dropna(), kde=True)
plt.title('Distribution of Fare')
plt.show()


# Box plots for 'Age' and 'Fare'
plt.figure(figsize=(12, 5))
plt.subplot(1, 2, 1)
sns.boxplot(y=df['Age'])
plt.title('Box Plot of Age')

plt.subplot(1, 2, 2)
sns.boxplot(y=df['Fare'])
plt.title('Box Plot of Fare')
plt.show()


# Scatter plot of 'Age' vs. 'Fare', colored by 'Pclass'
plt.figure(figsize=(8, 6))
sns.scatterplot(x='Age', y='Fare', hue='Pclass', data=df)
plt.title('Age vs. Fare (colored by Pclass)')
plt.show()


# Bar charts for categorical features
plt.figure(figsize=(15, 5))

plt.subplot(1, 3, 1)
sns.countplot(x='Embarked', data=df)
plt.title('Embarked')

plt.subplot(1, 3, 2)
sns.countplot(x='Sex', data=df)
plt.title('Sex')

plt.subplot(1, 3, 3)
sns.countplot(x='Pclass', data=df)
plt.title('Pclass')

plt.tight_layout()
plt.show()

"""## Summary:

### 1. Q&A

* **What are the missing values in the dataset?**  The 'Age' column has 86 missing values (20.57%), 'Cabin' has 327 (78.23%), and 'Fare' has 1 (0.24%).
* **Are there any outliers in the dataset?** Yes, outliers were detected in the 'Age' and 'Fare' columns using the IQR method.  Two ages (67.0 and 76.0) and several 'Fare' values, including the maximum fare (512.3292), were identified as potential outliers.  Visualizations (box plots and histograms) confirmed the presence of these outliers.


### 2. Data Analysis Key Findings

* **Significant Missing Data in 'Cabin':** The 'Cabin' column has a very high percentage of missing values (78.23%), suggesting it might not be very useful for analysis without significant imputation or removal.
* **Outliers in 'Fare':**  Multiple 'Fare' values are identified as outliers, with the maximum fare (512.33) being a prominent example.  These outliers might disproportionately influence certain analyses.
* **Outliers in 'Age':** Two ages (67.0 and 76.0) are identified as outliers.
* **Categorical Feature Distributions:**  The 'Embarked' column shows 'S' as the most frequent port of embarkation, 'Sex' is roughly balanced between 'male' and 'female', and 'Pclass' shows a distribution across the three passenger classes.


### 3. Insights or Next Steps

* **Handle Missing Data and Outliers:** Address the substantial missing data in the 'Cabin' column (consider imputation, removal, or creating a new indicator variable for missingness).  Investigate the 'Fare' outliers to determine if they are valid data points or errors. Consider transforming 'Fare' (e.g., log transformation) to mitigate the impact of outliers.  Decide on an appropriate strategy to handle the missing values in 'Age' (e.g., imputation using mean/median/mode or more sophisticated methods).
* **Further Exploratory Data Analysis:** Explore relationships between features, particularly 'Age', 'Fare', 'Pclass', 'Sex', and 'Embarked' in relation to the target variable (if one exists).  Visualize these relationships to gain deeper insights.

"""

#1. Handling Missing Values

#Cabin Column: Since the 'Cabin' column has a high percentage of missing values (78.23%), it's best to drop it.
 #permanent change

df['Age'].nunique()

df["Age"].isnull().sum()

#Age Column: We can impute the missing values in the 'Age' column using the median age.
df['Age'].fillna(df['Age'].median(), inplace=True)
df['Fare'].fillna(df['Fare'].median(), inplace=True)
df.isnull().sum()

#remove cabin
df.drop('Cabin', axis=1, inplace=True)
df.isnull().sum()

#remove PassengerId cause no affect on analysis
df.drop('PassengerId', axis=1, inplace=True)
df.isnull().sum()

df.columns

#remove Name and Ticket cause no affect on analysis and encoding would create lots
# of unnecessary columns
df.drop(['Name','Ticket'], axis=1, inplace=True)

df['Embarked'].isnull().sum()

#Embarked Column: If there are any missing values in 'Embarked', we can impute them with the most frequent value (mode).
df['Embarked'].fillna(df['Embarked'].mode()[0], inplace=True)

df.describe()

#clip values of fare column
df['Fare'] = np.clip(df['Fare'], a_min = 2, a_max =100)

df.describe()

Q1 = df['Age'].quantile(0.25)
Q3 = df['Age'].quantile(0.75)
iqr=Q3-Q1
min=Q1- 1.5* iqr
max=Q3+ 1.5* iqr
print(min,"------",max)
df['Age'] = np.clip(df['Age'], a_min = 13, a_max =76)

df.describe()

# duplicate in data set
df.duplicated()

#2. Handling Outliers
#Fare Column: We can winsorize the 'Fare' column to cap the extreme values. Winsorizing replaces extreme values with a specified percentile.

df['Fare'] = winsorize(df['Fare'], limits=[0, 0.1])

#Age Column: We can also winsorize the 'Age' column if needed.
df['Age'] = winsorize(df['Age'], limits=[0.05, 0.05])  # Cap top and bottom 5% of Age values

"""# Reasoning:

Dropping 'Cabin': Due to the significant number of missing values, imputing or trying to recover information from the 'Cabin' column might introduce bias or noise. It's more reliable to remove it for this analysis.


Imputing 'Age' and 'Embarked': Using the median for 'Age' and mode for 'Embarked' provides reasonable estimates for the missing values without significantly altering the data distribution.


Winsorizing 'Fare' and 'Age': Winsorizing limits the influence of extreme values (outliers) by replacing them with less extreme values. This helps to make the analysis more robust to outliers.


# Important Considerations:

Data Understanding: Always carefully consider the nature of your data and the implications of handling missing values and outliers. The chosen methods should align with your specific analysis goals.


Alternative Approaches: There are other ways to handle missing values and outliers, such as using more advanced imputation techniques or transforming variables. Explore these options if necessary.


Validation: After handling missing values and outliers, it's crucial to reassess the data and the impact of the changes on your analysis results.
"""

df

df["Sex"].value_counts() # nominal----one hot

categorical_columns = df.select_dtypes(include=['object']).columns
df = pd.get_dummies(df, columns = categorical_columns, drop_first=True)
display(df.head())

#historgram of scaled data
df.hist(figsize=(20,20))
plt.show()

#z score normalisation/ standardisation--- shape of the data -- sclae data
numerical_columns = df.select_dtypes(include=['number']).columns

scaler = StandardScaler() # z score
df[numerical_columns] = scaler.fit_transform(df[numerical_columns])

min_max_scale = MinMaxScaler() # 0---1 scaler
df[numerical_columns] = min_max_scale.fit_transform(df[numerical_columns])

display(df.head())

df.describe()

numerical_df = df.select_dtypes(include=['number'])
correlation_matrix = numerical_df.corr()
display(correlation_matrix)

plt.figure(figsize=(8,6))
sns.heatmap(correlation_matrix, annot=True, fmt=".2f")
plt.title("Correlation Matrix of Numerical Features")
plt.show()

"""## Summary:

### Data Analysis Key Findings

*   There is a strong negative correlation (-0.577) between `Pclass` and `Fare`, indicating that higher passenger classes (lower `Pclass`) are associated with higher fares.
*   A moderate negative correlation (-0.441) exists between `Pclass` and `Age`, suggesting older passengers tend to be in higher classes.
*   There is a moderate positive correlation (0.327) between `Age` and `Fare`.
*   A moderate positive correlation (0.307) is observed between `SibSp` and `Parch`.
*   A heatmap was successfully generated to visualize the correlation matrix of the numerical features.

### Insights or Next Steps

*   The strong correlations identified, particularly between `Pclass`, `Fare`, and `Age`, could be important features for predictive modeling tasks.
*   Consider investigating the relationships visually using scatter plots for pairs with moderate to strong correlations to understand the nature of these relationships better.


### Data Analysis Key Findings

*   The dataset initially contained missing values in the 'Age', 'Fare', and 'Cabin' columns.
*   Missing values in 'Age' and 'Fare' were imputed using the mean of their respective columns.
*   The 'Cabin' column was dropped due to a significant number of missing values (327 out of 418 rows).
*   Categorical columns ('Name', 'Sex', 'Ticket', 'Embarked') were successfully one-hot encoded, resulting in a significant increase in the number of columns (from 10 to 788).
*   Numerical columns ('Age', 'Fare', 'SibSp', 'Parch', 'Pclass') were successfully standardized and then normalized, with their values now scaled to a range between 0 and 1.

### Insights or Next Steps

*   The high dimensionality after one-hot encoding suggests exploring dimensionality reduction techniques like PCA or selecting relevant features to improve model performance and reduce computational cost.
*   Further analysis could explore the relationships between the scaled numerical features and the target variable (if available) or investigate potential correlations between the newly created one-hot encoded features.

"""